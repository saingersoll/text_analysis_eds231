---
title: "Lab 4"
author: "Sofia Ingersoll"
date: "2024-05-07"
output: html_document
---

Lab 4 Assignment: Due May 7 at 11:59pm

```{r set_up, message = FALSE, warning = FALSE}
#knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

# reproducibility
set.seed(1234)

# load libraries
# naive-bayes
library(vip)
library(discrim) 
library(tidytext)
library(tidyverse)
library(tidymodels)
library(textrecipes)


library(doParallel)  # for parallel backend to foreach
library(foreach)     # for parallel processing with for loops
library(xgboost)

# load data
urlfile ="https://raw.githubusercontent.com/MaRo406/EDS-231-text-sentiment/main/data/climbing_reports_model_dat.csv"
incidents_df<-readr::read_csv(url(urlfile),
                              show_col_types = FALSE)
```

```{r split-data}
incidents2class <- incidents_df %>%
  mutate(fatal = factor(if_else(
                        is.na(Deadly),
                        "non-fatal", "fatal")))


incidents_split <- initial_split(incidents2class,
                                 prop = 0.8,
                                 strata = fatal)

incidents_train <- training(incidents_split)
incidents_test <- testing(incidents_split)
```

```{r recipe}
incidents_rec <- recipe(fatal ~ Text, data = incidents_train)
```

```{r pre-process}
recipe <- incidents_rec %>%
  step_tokenize(Text) %>%
  # max 5000 is perfect performance
  step_tokenfilter(Text, max_tokens = 1000) %>%
  step_tfidf(Text)
```

1. Select another classification algorithm.  
2. Conduct an initial out-of-the-box model fit on the training data and prediction on the test data.  Assess the performance of this initial model. 
3. Select the relevant hyperparameters for your algorithm and tune your model.

4. Conduct a model fit using your newly tuned model specification.  How does it compare to your out-of-the-box model?

5.
  a. Use variable importance to determine the terms most highly associated with non-fatal reports?  What about terms associated with fatal reports? OR
  b. If you aren't able to get at variable importance with your selected algorithm, instead tell me how you might in theory be able to do it. Or how you might determine the important distinguishing words in some other way. 

6. Predict fatality of the reports in the test set.  Compare this prediction performance to that of the Naive Bayes and Lasso models.  Why do you think your model performed as it did, relative to the other two?

```{r}
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# ----                       Tuning Decision Tree                           ----
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# new spec, tell the model that we are tuning hyperparams
tree_spec_tune <- decision_tree(
  cost_complexity = tune(),
  tree_depth = tune(),
  min_n = tune()
) %>% 
  set_engine('rpart') %>% 
  set_mode('classification')

# info about the possible range of this hyperparameter valuea
# 5 x 5 x 5 grid of the parameters for cross validation
tree_grid <- grid_regular(cost_complexity(),
                          tree_depth(),
                          min_n(),
                          levels = 5)

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# ----                           Workflow                                   ----
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# create workflow
wf_tree_tune <- workflow() %>% 
  add_recipe(recipe) %>% 
  add_model(tree_spec_tune)

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# ----                        Cross Validation                              ----
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#set up k-fold cv. This can be used for all the algorithms
cv_folds <- incidents_train %>% 
  vfold_cv(v = 10)

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# ----                         Parallel Trees                               ----
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# in parallel, create a set of decision trees
doParallel::registerDoParallel() 

system.time(
  tree_rs <- tune_grid(
    wf_tree_tune,
    resamples = cv_folds,
    grid = tree_grid,
    metrics = metric_set(accuracy)
  )
)

#tree_rs

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# ----                         Finalize Workflow                            ----
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# finalize workflow using the best tree and tuning
final_tree <- finalize_workflow(wf_tree_tune,
                                select_best(tree_rs))

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# ----                             Fit Model                                ----
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#similar functions here.
final_tree_fit <- fit(final_tree,
                      data = incidents_train) 

# get prediction for test 
test_predict_tree <- predict(final_tree_fit, incidents_test) %>% 
  # bind to testing column
  bind_cols(incidents_test) %>%  
  mutate(genre = as.factor(fatal))

# get testing prediction probabilities
test_predict_tree2 <- predict(final_tree_fit,
                              incidents_test,
                              type = "prob") %>% 
  # bind to testing column
  bind_cols(incidents_test) %>%  
  mutate(genre = as.factor(fatal))
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# ----                          Evaluate Model                              ----
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# get accuracy of testing prediction
tree_accuracy <- accuracy(test_predict_tree, truth = fatal, estimate = .pred_class) 

#tree_accuracy

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# ----                        Visual of Fit Model                          ----
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Visualize fit model
final_tree_fit %>% 
  vip(geom = 'col',
      aesthetics = list(fill = 'midnightblue'),
      alpha = 0.8) +
  scale_y_continuous(expand = c(0,0)) 

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# ----                    Visualize Parallel Trees                          ----
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# visualize our parallel trees model
autoplot(tree_rs) +
  theme_bw()
```
